{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3973924d",
   "metadata": {},
   "source": [
    "Normaliza nombres de columnas: minúsculas, sin espacios ni acentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5af88c41",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m ruta_excel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw/Sales report completa.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(ruta_excel)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:508\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 508\u001b[0m     data \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mparse(\n\u001b[0;32m    509\u001b[0m         sheet_name\u001b[38;5;241m=\u001b[39msheet_name,\n\u001b[0;32m    510\u001b[0m         header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m    511\u001b[0m         names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m    512\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m    513\u001b[0m         usecols\u001b[38;5;241m=\u001b[39musecols,\n\u001b[0;32m    514\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    515\u001b[0m         converters\u001b[38;5;241m=\u001b[39mconverters,\n\u001b[0;32m    516\u001b[0m         true_values\u001b[38;5;241m=\u001b[39mtrue_values,\n\u001b[0;32m    517\u001b[0m         false_values\u001b[38;5;241m=\u001b[39mfalse_values,\n\u001b[0;32m    518\u001b[0m         skiprows\u001b[38;5;241m=\u001b[39mskiprows,\n\u001b[0;32m    519\u001b[0m         nrows\u001b[38;5;241m=\u001b[39mnrows,\n\u001b[0;32m    520\u001b[0m         na_values\u001b[38;5;241m=\u001b[39mna_values,\n\u001b[0;32m    521\u001b[0m         keep_default_na\u001b[38;5;241m=\u001b[39mkeep_default_na,\n\u001b[0;32m    522\u001b[0m         na_filter\u001b[38;5;241m=\u001b[39mna_filter,\n\u001b[0;32m    523\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    524\u001b[0m         parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[0;32m    525\u001b[0m         date_parser\u001b[38;5;241m=\u001b[39mdate_parser,\n\u001b[0;32m    526\u001b[0m         date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m    527\u001b[0m         thousands\u001b[38;5;241m=\u001b[39mthousands,\n\u001b[0;32m    528\u001b[0m         decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m    529\u001b[0m         comment\u001b[38;5;241m=\u001b[39mcomment,\n\u001b[0;32m    530\u001b[0m         skipfooter\u001b[38;5;241m=\u001b[39mskipfooter,\n\u001b[0;32m    531\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    532\u001b[0m     )\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    534\u001b[0m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_close:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1616\u001b[0m, in \u001b[0;36mExcelFile.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m   1576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\n\u001b[0;32m   1577\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1578\u001b[0m     sheet_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1596\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[0;32m   1597\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, DataFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, DataFrame]:\n\u001b[0;32m   1598\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m \u001b[38;5;124;03m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1614\u001b[0m \u001b[38;5;124;03m    >>> file.parse()  # doctest: +SKIP\u001b[39;00m\n\u001b[0;32m   1615\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mparse(\n\u001b[0;32m   1617\u001b[0m         sheet_name\u001b[38;5;241m=\u001b[39msheet_name,\n\u001b[0;32m   1618\u001b[0m         header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   1619\u001b[0m         names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m   1620\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   1621\u001b[0m         usecols\u001b[38;5;241m=\u001b[39musecols,\n\u001b[0;32m   1622\u001b[0m         converters\u001b[38;5;241m=\u001b[39mconverters,\n\u001b[0;32m   1623\u001b[0m         true_values\u001b[38;5;241m=\u001b[39mtrue_values,\n\u001b[0;32m   1624\u001b[0m         false_values\u001b[38;5;241m=\u001b[39mfalse_values,\n\u001b[0;32m   1625\u001b[0m         skiprows\u001b[38;5;241m=\u001b[39mskiprows,\n\u001b[0;32m   1626\u001b[0m         nrows\u001b[38;5;241m=\u001b[39mnrows,\n\u001b[0;32m   1627\u001b[0m         na_values\u001b[38;5;241m=\u001b[39mna_values,\n\u001b[0;32m   1628\u001b[0m         parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[0;32m   1629\u001b[0m         date_parser\u001b[38;5;241m=\u001b[39mdate_parser,\n\u001b[0;32m   1630\u001b[0m         date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   1631\u001b[0m         thousands\u001b[38;5;241m=\u001b[39mthousands,\n\u001b[0;32m   1632\u001b[0m         comment\u001b[38;5;241m=\u001b[39mcomment,\n\u001b[0;32m   1633\u001b[0m         skipfooter\u001b[38;5;241m=\u001b[39mskipfooter,\n\u001b[0;32m   1634\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1635\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[0;32m   1636\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:778\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m    775\u001b[0m     sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sheet_by_index(asheetname)\n\u001b[0;32m    777\u001b[0m file_rows_needed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calc_rows(header, index_col, skiprows, nrows)\n\u001b[1;32m--> 778\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sheet_data(sheet, file_rows_needed)\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(sheet, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# pyxlsb opens two TemporaryFiles\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     sheet\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:615\u001b[0m, in \u001b[0;36mOpenpyxlReader.get_sheet_data\u001b[1;34m(self, sheet, file_rows_needed)\u001b[0m\n\u001b[0;32m    613\u001b[0m data: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[Scalar]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    614\u001b[0m last_row_with_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 615\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_number, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sheet\u001b[38;5;241m.\u001b[39mrows):\n\u001b[0;32m    616\u001b[0m     converted_row \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_cell(cell) \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m row]\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m converted_row \u001b[38;5;129;01mand\u001b[39;00m converted_row[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    618\u001b[0m         \u001b[38;5;66;03m# trim trailing empty elements\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:85\u001b[0m, in \u001b[0;36mReadOnlyWorksheet._cells_by_row\u001b[1;34m(self, min_col, min_row, max_col, max_row, values_only)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_source() \u001b[38;5;28;01mas\u001b[39;00m src:\n\u001b[0;32m     78\u001b[0m     parser \u001b[38;5;241m=\u001b[39m WorkSheetParser(src,\n\u001b[0;32m     79\u001b[0m                              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shared_strings,\n\u001b[0;32m     80\u001b[0m                              data_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mdata_only,\n\u001b[0;32m     81\u001b[0m                              epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mepoch,\n\u001b[0;32m     82\u001b[0m                              date_formats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39m_date_formats,\n\u001b[0;32m     83\u001b[0m                              timedelta_formats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39m_timedelta_formats)\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mparse():\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m max_row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m idx \u001b[38;5;241m>\u001b[39m max_row:\n\u001b[0;32m     87\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:156\u001b[0m, in \u001b[0;36mparse\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\xml\\etree\\ElementTree.py:1238\u001b[0m, in \u001b[0;36miterparse.<locals>.iterator\u001b[1;34m(source)\u001b[0m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m pullparser\u001b[38;5;241m.\u001b[39mread_events()\n\u001b[0;32m   1237\u001b[0m \u001b[38;5;66;03m# load event buffer\u001b[39;00m\n\u001b[1;32m-> 1238\u001b[0m data \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m16\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m)\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\zipfile\\__init__.py:989\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[1;32m--> 989\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read1(n)\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\zipfile\\__init__.py:1065\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_type \u001b[38;5;241m==\u001b[39m ZIP_DEFLATED:\n\u001b[0;32m   1064\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMIN_READ_SIZE)\n\u001b[1;32m-> 1065\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39mdecompress(data, n)\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39meof \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m                  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m                  \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail)\n\u001b[0;32m   1069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "ruta_excel = \"raw/Sales report completa.xlsx\"\n",
    "df = pd.read_excel(ruta_excel)\n",
    "print(df.head(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c558328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['numero_venta', 'mes_salida', 'dia_salida', 'ano_salida', 'mes_entrega',\n",
      "       'dia_entrega', 'ano_entrega', 'metodo_envio', 'numero_cliente',\n",
      "       'nombre_cliente', 'segmento', 'ciudad', 'estado', 'pais', 'id_producto',\n",
      "       'ventas', 'cantidad', 'descuento', 'utilidad', 'costo_envio',\n",
      "       'prioridad_envio'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def estandarizar_columnas(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(\" \", \"_\")\n",
    "         .str.replace(\"-\", \"_\")\n",
    "        .str.normalize(\"NFKD\")\n",
    "        .str.encode(\"ascii\", errors=\"ignore\")\n",
    "        .str.decode(\"utf-8\")\n",
    "    )\n",
    "    return df \n",
    "# Aplicar la función al dataframe que ya cargaste\n",
    "df = estandarizar_columnas(df)\n",
    "\n",
    "# Mostrar las nuevas columnas estandarizadas\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898dd98c",
   "metadata": {},
   "source": [
    "Estandariza las tres primeras hojas del archivo Excel (Ventas Supermercado, Regiones, y Productos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc40b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas en hoja Ventas: ['numero_venta', 'mes_salida', 'dia_salida', 'ano_salida', 'mes_entrega', 'dia_entrega', 'ano_entrega', 'metodo_envio', 'numero_cliente', 'nombre_cliente', 'segmento', 'ciudad', 'estado', 'pais', 'id_producto', 'ventas', 'cantidad', 'descuento', 'utilidad', 'costo_envio', 'prioridad_envio']\n",
      "Columnas en hoja Regiones: ['pais', 'mercado', 'region']\n",
      "Columnas en hoja Productos: ['id_producto', 'categoria', 'sub_categoria', 'nombre_producto']\n"
     ]
    }
   ],
   "source": [
    "# Cargar cada hoja por separado\n",
    "ventas_df = pd.read_excel(ruta_excel, sheet_name=0)          # Primera hoja (Ventas Supermercado)\n",
    "regiones_df = pd.read_excel(ruta_excel, sheet_name=\"Regiones\")\n",
    "productos_df = pd.read_excel(ruta_excel, sheet_name=\"Productos\")\n",
    "\n",
    "# Estandarizar las columnas de cada uno\n",
    "ventas_df = estandarizar_columnas(ventas_df)\n",
    "regiones_df = estandarizar_columnas(regiones_df)\n",
    "productos_df = estandarizar_columnas(productos_df)\n",
    "\n",
    "# Mostrar los nombres de columnas como verificación\n",
    "print(\"Columnas en hoja Ventas:\", ventas_df.columns.tolist())\n",
    "print(\"Columnas en hoja Regiones:\", regiones_df.columns.tolist())\n",
    "print(\"Columnas en hoja Productos:\", productos_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052fe04a",
   "metadata": {},
   "source": [
    "Elimina los espacios en blanco innecesarios de la columna \"Método de envío\" Ejemplo: \" Standard  \tClass \" por \"Standard Class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c39ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Standard Class' 'Second Class' 'First Class' 'Same Day']\n"
     ]
    }
   ],
   "source": [
    "def limpiar_espacios_metodo_envio(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if 'metodo_envio' in df.columns:\n",
    "        df['metodo_envio'] = df['metodo_envio'].astype(str).str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "    else:\n",
    "        print(\"La columna 'metodo_envio' no existe en el DataFrame.\")\n",
    "    return df\n",
    "\n",
    "# Aplicar la función\n",
    "df = limpiar_espacios_metodo_envio(df)\n",
    "\n",
    "# Ver los valores únicos de la columna después de limpiar\n",
    "print(df['metodo_envio'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a3f250",
   "metadata": {},
   "source": [
    "Unificar Mes/Dia/Año de las fecha_envio y fecha_entrega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b42c496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  fecha_salida fecha_entrega\n",
      "0   2011-01-01    2011-01-06\n",
      "1   2011-01-01    2011-01-08\n",
      "2   2011-01-01    2011-01-05\n",
      "3   2011-01-01    2011-01-05\n",
      "4   2011-01-01    2011-01-08\n",
      "Index(['numero_venta', 'mes_salida', 'dia_salida', 'ano_salida', 'mes_entrega',\n",
      "       'dia_entrega', 'ano_entrega', 'metodo_envio', 'numero_cliente',\n",
      "       'nombre_cliente', 'segmento', 'ciudad', 'estado', 'pais', 'id_producto',\n",
      "       'ventas', 'cantidad', 'descuento', 'utilidad', 'costo_envio',\n",
      "       'prioridad_envio', 'fecha_salida', 'fecha_entrega'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def convertir_fechas(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Convertir las columnas de año, mes y día a números enteros (permitiendo nulos)\n",
    "    for col in ['ano_salida', 'mes_salida', 'dia_salida', 'ano_entrega', 'mes_entrega', 'dia_entrega']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64')  # 'Int64' permite NaN\n",
    "\n",
    "    # Crear columna de fecha_salida si existen las tres columnas necesarias\n",
    "    if {'ano_salida', 'mes_salida', 'dia_salida'}.issubset(df.columns):\n",
    "        df['fecha_salida'] = pd.to_datetime(\n",
    "            df[['ano_salida', 'mes_salida', 'dia_salida']].rename(\n",
    "                columns={\n",
    "                    'ano_salida': 'year',\n",
    "                    'mes_salida': 'month',\n",
    "                    'dia_salida': 'day'\n",
    "                }\n",
    "            ),\n",
    "            errors='coerce'\n",
    "        )\n",
    "        \n",
    "    # Crear columna de fecha_entrega si existen las tres columnas necesarias\n",
    "    if {'ano_entrega', 'mes_entrega', 'dia_entrega'}.issubset(df.columns):\n",
    "        df['fecha_entrega'] = pd.to_datetime(\n",
    "            df[['ano_entrega', 'mes_entrega', 'dia_entrega']].rename(\n",
    "                columns={\n",
    "                    'ano_entrega': 'year',\n",
    "                    'mes_entrega': 'month',\n",
    "                    'dia_entrega': 'day'\n",
    "                }\n",
    "            ),\n",
    "            errors='coerce'\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "# Aplicar la función al DataFrame\n",
    "df = convertir_fechas(df)\n",
    "\n",
    "# Verificar las nuevas columnas de fecha\n",
    "print(df[['fecha_salida', 'fecha_entrega']].head())\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fadae6e",
   "metadata": {},
   "source": [
    "Agrega una columna con los dias_transcurridos\" entre la Fecha Salida y Fecha \n",
    "Entrega. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc6678f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  fecha_salida fecha_entrega  duracion_envio\n",
      "0   2011-01-01    2011-01-06               5\n",
      "1   2011-01-01    2011-01-08               7\n",
      "2   2011-01-01    2011-01-05               4\n",
      "3   2011-01-01    2011-01-05               4\n",
      "4   2011-01-01    2011-01-08               7\n"
     ]
    }
   ],
   "source": [
    "def calcular_duracion_envio(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if {'fecha_salida', 'fecha_entrega'}.issubset(df.columns):\n",
    "        df['duracion_envio'] = (df['fecha_entrega'] - df['fecha_salida']).dt.days\n",
    "    else:\n",
    "        print(\"Las columnas 'fecha_salida' y/o 'fecha_entrega' no existen en el DataFrame.\")\n",
    "    return df\n",
    "\n",
    "# Aplicar la función al DataFrame\n",
    "df = calcular_duracion_envio(df)\n",
    "\n",
    "# Verificar resultado\n",
    "print(df[['fecha_salida', 'fecha_entrega', 'duracion_envio']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc7eb48",
   "metadata": {},
   "source": [
    "Agrega una columna con  id_venta unificando y pasando a mayusc: 2 iniciales de \n",
    "\"País\", \"Año Salida\" y \"Número Venta\" (ejemplo: Al-2011-2040). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "929fbe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        pais  ano_salida  numero_venta       id_venta\n",
      "0    Algeria        2011          2040   AL-2011-2040\n",
      "1  Australia        2011         47883  AU-2011-47883\n"
     ]
    }
   ],
   "source": [
    "def crear_id_venta(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if {'pais', 'ano_salida', 'numero_venta'}.issubset(df.columns):\n",
    "        # Asegurar que los datos sean cadenas y manejar valores faltantes\n",
    "        df['id_venta'] = (\n",
    "            df['pais'].astype(str).str.strip().str[:2]      # Primeras 2 letras del país\n",
    "            + '-' +\n",
    "            df['ano_salida'].astype(str).str.strip()        # Año de salida\n",
    "            + '-' +\n",
    "            df['numero_venta'].astype(str).str.strip()      # Número de venta\n",
    "        ).str.upper()  # Convertir todo a mayúsculas\n",
    "    else:\n",
    "        print(\"Faltan una o más columnas necesarias: 'pais', 'ano_salida', 'numero_venta'\")\n",
    "    return df\n",
    "\n",
    "# Aplicar la función\n",
    "df = crear_id_venta(df)\n",
    "\n",
    "# Verificar las primeras filas\n",
    "print(df[['pais', 'ano_salida', 'numero_venta', 'id_venta']].head(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4040bf6d",
   "metadata": {},
   "source": [
    "Agrega una columna con id_cliente unificando: Inicial Nombre, Inicial Apellido y \n",
    "Número Cliente (ejemplo: TB-11280).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fa2c21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nombre_cliente  numero_cliente id_cliente\n",
      "0  Toby Braunhardt           11280   TB-11280\n",
      "1      Joseph Holt           15985   JH-15985\n"
     ]
    }
   ],
   "source": [
    "def crear_id_cliente_desde_nombre_completo(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if {'nombre_cliente', 'numero_cliente'}.issubset(df.columns):\n",
    "        # Separar nombre y apellido suponiendo que hay al menos dos palabras\n",
    "        partes = df['nombre_cliente'].astype(str).str.strip().str.split(expand=True)\n",
    "\n",
    "        # Tomar primera palabra como nombre y segunda como apellido (si existen)\n",
    "        df['inicial_nombre'] = partes[0].str[0]\n",
    "        df['inicial_apellido'] = partes[1].str[0] if partes.shape[1] > 1 else ''\n",
    "\n",
    "        # Crear el id_cliente combinando iniciales + número_cliente\n",
    "        df['id_cliente'] = (\n",
    "            df['inicial_nombre'].fillna('') +\n",
    "            df['inicial_apellido'].fillna('') +\n",
    "            '-' +\n",
    "            df['numero_cliente'].astype(str).str.strip()\n",
    "        ).str.upper()\n",
    "\n",
    "        # (Opcional) Eliminar las columnas auxiliares si no se quieren mostrar\n",
    "        df.drop(columns=['inicial_nombre', 'inicial_apellido'], inplace=True)\n",
    "\n",
    "    else:\n",
    "        print(\"Faltan columnas necesarias: 'nombre_cliente' y/o 'numero_cliente'\")\n",
    "    return df\n",
    "\n",
    "# Aplicar la función\n",
    "df = crear_id_cliente_desde_nombre_completo(df)\n",
    "\n",
    "# Verificar resultado\n",
    "print(df[['nombre_cliente', 'numero_cliente', 'id_cliente']].head(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe6e747",
   "metadata": {},
   "source": [
    "Agrega las columnas mercado y región obteniéndose de la columna País y la Hoja \n",
    "Regiones dentro del mismo archivo excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b3d039a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   numero_venta  mes_salida  dia_salida  ano_salida  mes_entrega  dia_entrega  \\\n",
      "0          2040           1           1        2011            1            6   \n",
      "1         47883           1           1        2011            1            8   \n",
      "\n",
      "   ano_entrega    metodo_envio  numero_cliente   nombre_cliente  ... cantidad  \\\n",
      "0         2011  Standard Class           11280  Toby Braunhardt  ...        2   \n",
      "1         2011  Standard Class           15985      Joseph Holt  ...        3   \n",
      "\n",
      "  descuento utilidad costo_envio prioridad_envio  fecha_salida  fecha_entrega  \\\n",
      "0       0.0  106.140       35.46          Medium    2011-01-01     2011-01-06   \n",
      "1       0.1   36.036        9.72          Medium    2011-01-01     2011-01-08   \n",
      "\n",
      "   duracion_envio       id_venta  id_cliente  \n",
      "0               5   AL-2011-2040    TB-11280  \n",
      "1               7  AU-2011-47883    JH-15985  \n",
      "\n",
      "[2 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "def agregar_mercado_region(df: pd.DataFrame, regiones_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    try:\n",
    "        # Asegurarse de que la columna 'pais' esté limpia en ambos DataFrames\n",
    "        df['pais'] = df['pais'].astype(str).str.strip()\n",
    "        regiones_df['pais'] = regiones_df['pais'].astype(str).str.strip()\n",
    "\n",
    "        # Unir los DataFrames por la columna 'pais'\n",
    "        df = df.merge(regiones_df[['pais', 'mercado', 'region']], on='pais', how='left')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al agregar mercado y región: {e}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Verificar las nuevas columnas\n",
    "print(df.head(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102a9b69",
   "metadata": {},
   "source": [
    "Agrega las columnas categoría, sub_categoría y nombre_producto obteniéndolas de la \n",
    "columna ID-Producto y la Hoja Productos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a2aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id_producto        categoria sub_categoria           nombre_producto\n",
      "0  OFF-TEN-10000025  Office Supplies       Storage       Tenex Lockers, Blue\n",
      "1   OFF-SU-10000618  Office Supplies      Supplies  Acme Trimmer, High Speed\n",
      "Index(['numero_venta', 'mes_salida', 'dia_salida', 'ano_salida', 'mes_entrega',\n",
      "       'dia_entrega', 'ano_entrega', 'metodo_envio', 'numero_cliente',\n",
      "       'nombre_cliente', 'segmento', 'ciudad', 'estado', 'pais', 'id_producto',\n",
      "       'ventas', 'cantidad', 'descuento', 'utilidad', 'costo_envio',\n",
      "       'prioridad_envio', 'fecha_salida', 'fecha_entrega', 'duracion_envio',\n",
      "       'id_venta', 'id_cliente', 'mercado', 'region', 'categoria_x',\n",
      "       'sub_categoria_x', 'nombre_producto_x', 'categoria_y',\n",
      "       'sub_categoria_y', 'nombre_producto_y', 'categoria', 'sub_categoria',\n",
      "       'nombre_producto'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def agregar_mercado_region(df: pd.DataFrame, regiones_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    try:\n",
    "        # Limpiar la columna 'pais' en ambos DataFrames\n",
    "        df['pais'] = df['pais'].astype(str).str.strip()\n",
    "        regiones_df['pais'] = regiones_df['pais'].astype(str).str.strip()\n",
    "\n",
    "        # Unir por 'pais'\n",
    "        df = df.merge(regiones_df[['pais', 'mercado', 'region']], on='pais', how='left')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al agregar mercado y región: {e}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Verificar resultado\n",
    "print(df[['id_producto', 'categoria', 'sub_categoria', 'nombre_producto']].drop_duplicates().head(2))\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814f821a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7887db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   utilidad resultado_venta\n",
      "0   106.140        Ganancia\n",
      "1    36.036        Ganancia\n",
      "2    29.640        Ganancia\n",
      "3   -26.055         Pérdida\n",
      "4    37.770        Ganancia\n"
     ]
    }
   ],
   "source": [
    "def agregar_resultado_venta(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    try:\n",
    "        # Verificar que exista la columna 'utilidad'\n",
    "        if 'utilidad' in df.columns:\n",
    "            df['resultado_venta'] = df['utilidad'].apply(\n",
    "                lambda x: 'Ganancia' if x > 0 else ('Pérdida' if x < 0 else 'Neutro')\n",
    "            )\n",
    "        else:\n",
    "            print(\"Columna 'utilidad' no encontrada en el DataFrame.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al agregar columna 'resultado_venta': {e}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "ventas_df = agregar_resultado_venta(ventas_df)\n",
    "\n",
    "# Verificamos el resultado\n",
    "print(ventas_df[['utilidad', 'resultado_venta']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0a3799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['numero_venta', 'mes_salida', 'dia_salida', 'ano_salida', 'mes_entrega',\n",
      "       'dia_entrega', 'ano_entrega', 'metodo_envio', 'numero_cliente',\n",
      "       'nombre_cliente', 'segmento', 'ciudad', 'estado', 'pais', 'id_producto',\n",
      "       'ventas', 'cantidad', 'descuento', 'utilidad', 'costo_envio',\n",
      "       'prioridad_envio', 'fecha_salida', 'fecha_entrega', 'duracion_envio',\n",
      "       'id_venta', 'id_cliente', 'mercado', 'region', 'categoria_x',\n",
      "       'sub_categoria_x', 'nombre_producto_x', 'categoria_y',\n",
      "       'sub_categoria_y', 'nombre_producto_y', 'categoria', 'sub_categoria',\n",
      "       'nombre_producto'],\n",
      "      dtype='object')\n",
      "   numero_venta  mes_salida  dia_salida  ano_salida  mes_entrega  dia_entrega  \\\n",
      "0          2040           1           1        2011            1            6   \n",
      "1         47883           1           1        2011            1            8   \n",
      "2          1220           1           1        2011            1            5   \n",
      "3       3647632           1           1        2011            1            5   \n",
      "4         47883           1           1        2011            1            8   \n",
      "\n",
      "   ano_entrega    metodo_envio  numero_cliente   nombre_cliente  ...   region  \\\n",
      "0         2011  Standard Class           11280  Toby Braunhardt  ...   Africa   \n",
      "1         2011  Standard Class           15985      Joseph Holt  ...  Oceania   \n",
      "2         2011    Second Class             735    Annie Thurman  ...     EMEA   \n",
      "3         2011    Second Class           14140     Eugene Moren  ...    North   \n",
      "4         2011  Standard Class           15985      Joseph Holt  ...  Oceania   \n",
      "\n",
      "       categoria_x sub_categoria_x            nombre_producto_x  \\\n",
      "0  Office Supplies         Storage          Tenex Lockers, Blue   \n",
      "1  Office Supplies        Supplies     Acme Trimmer, High Speed   \n",
      "2  Office Supplies         Storage      Tenex Box, Single Width   \n",
      "3  Office Supplies           Paper  Enermax Note Cards, Premium   \n",
      "4        Furniture     Furnishings   Eldon Light Bulb, Duo Pack   \n",
      "\n",
      "       categoria_y  sub_categoria_y            nombre_producto_y  \\\n",
      "0  Office Supplies          Storage          Tenex Lockers, Blue   \n",
      "1  Office Supplies         Supplies     Acme Trimmer, High Speed   \n",
      "2  Office Supplies          Storage      Tenex Box, Single Width   \n",
      "3  Office Supplies            Paper  Enermax Note Cards, Premium   \n",
      "4        Furniture      Furnishings   Eldon Light Bulb, Duo Pack   \n",
      "\n",
      "         categoria  sub_categoria              nombre_producto  \n",
      "0  Office Supplies        Storage          Tenex Lockers, Blue  \n",
      "1  Office Supplies       Supplies     Acme Trimmer, High Speed  \n",
      "2  Office Supplies        Storage      Tenex Box, Single Width  \n",
      "3  Office Supplies          Paper  Enermax Note Cards, Premium  \n",
      "4        Furniture    Furnishings   Eldon Light Bulb, Duo Pack  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccbd762",
   "metadata": {},
   "source": [
    "Salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b399d9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos exportados correctamente:\n",
      "✔ Excel: ../data/processed\\sales_report_final.xlsx\n",
      "✔ CSV: ../data/processed\\sales_report_final.csv\n"
     ]
    }
   ],
   "source": [
    "# Crear carpeta si no existe\n",
    "import os\n",
    "\n",
    "# Definir ruta de salida\n",
    "output_folder = \"../data/processed\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Rutas completas para guardar\n",
    "ruta_excel_final = os.path.join(output_folder, \"sales_report_final.xlsx\")\n",
    "ruta_csv_final = os.path.join(output_folder, \"sales_report_final.csv\")\n",
    "\n",
    "# Guardar en formato Excel\n",
    "df.to_excel(ruta_excel_final, index=False)\n",
    "\n",
    "# Guardar en formato CSV\n",
    "df.to_csv(ruta_csv_final, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"Archivos exportados correctamente:\")\n",
    "print(\"✔ Excel:\", ruta_excel_final)\n",
    "print(\"✔ CSV:\", ruta_csv_final)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
